{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmgbwQ0AOb3b",
        "outputId": "43698790-7125-4b6d-eb1a-b78bf73ebe1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.4)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.12/dist-packages (0.20.0)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.48.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from folium) (0.8.1)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.12/dist-packages (from folium) (3.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from folium) (2.32.4)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.12/dist-packages (from folium) (2025.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->folium) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "# Run this cell once to install required packages (may take a minute)\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn xgboost folium shap pyarrow\n",
        "\n",
        "# Imports\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
        "from sklearn.calibration import calibration_curve\n",
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "import shap\n",
        "plt.style.use('seaborn-v0_8') # Updated style name\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration: change filename if needed\n",
        "!unzip accidents_joined.zip\n",
        "FNAME = \"accidents_joined.csv\"\n",
        "# replace if your file name differs\n",
        "\n",
        "# Load\n",
        "df = pd.read_csv(FNAME, parse_dates=['timestamp'], infer_datetime_format=True)\n",
        "\n",
        "# Basic required columns check\n",
        "required = {'timestamp','lat','lon','is_accident'}\n",
        "if not required.issubset(set(df.columns)):\n",
        "    raise ValueError(f\"CSV must contain columns: {required}. Found: {set(df.columns)}\")\n",
        "\n",
        "# Basic preprocessing & feature creation\n",
        "df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "df['hour'] = df['timestamp'].dt.hour\n",
        "df['dayofweek'] = df['timestamp'].dt.dayofweek  # 0=Mon\n",
        "df['month'] = df['timestamp'].dt.month\n",
        "df['is_weekend'] = df['dayofweek'].isin([5,6]).astype(int)\n",
        "\n",
        "# cyclical encoding for time features\n",
        "df['hour_sin'] = np.sin(2*np.pi*df['hour']/24)\n",
        "df['hour_cos'] = np.cos(2*np.pi*df['hour']/24)\n",
        "df['dow_sin'] = np.sin(2*np.pi*df['dayofweek']/7)\n",
        "df['dow_cos'] = np.cos(2*np.pi*df['dayofweek']/7)\n",
        "\n",
        "# spatial cell id: simple rounded lat/lon (approx grid)\n",
        "df['cell_lat'] = df['lat'].round(3)\n",
        "df['cell_lon'] = df['lon'].round(3)\n",
        "df['cell_id'] = df['cell_lat'].astype(str) + \"_\" + df['cell_lon'].astype(str)\n",
        "\n",
        "# create a basic historic accident rate per cell (all time)\n",
        "cell_counts = df.groupby('cell_id')['is_accident'].sum().rename('cell_accidents')\n",
        "cell_totals = df.groupby('cell_id').size().rename('cell_total')\n",
        "cell_stats = pd.concat([cell_counts, cell_totals], axis=1)\n",
        "cell_stats['cell_rate'] = cell_stats['cell_accidents'] / cell_stats['cell_total']\n",
        "df = df.merge(cell_stats[['cell_rate']], left_on='cell_id', right_index=True, how='left')\n",
        "\n",
        "# If weather columns exist, ensure numeric\n",
        "for c in ['precip','temp','visibility','wind_speed']:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "\n",
        "# Fill small NaNs if any\n",
        "df.fillna({'precip':0,'temp':df.get('temp', df['lat']).median() if 'temp' in df.columns else 0}, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqLESIBRO4KT",
        "outputId": "cc96fd53-3b4c-42c8-941f-27186e68e478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  accidents_joined.zip\n",
            "replace accidents_joined.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "hour_counts = df.groupby('hour')['is_accident'].sum()\n",
        "sns.lineplot(x=hour_counts.index, y=hour_counts.values, marker='o')\n",
        "plt.title('Accidents by Hour of Day')\n",
        "plt.xlabel('Hour (0-23)')\n",
        "plt.ylabel('Number of Accidents')\n",
        "plt.xticks(range(0,24))\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nncE2SY2O4M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "dow_counts = df.groupby('dayofweek')['is_accident'].sum()\n",
        "sns.barplot(x=['Mon','Tue','Wed','Thu','Fri','Sat','Sun'], y=dow_counts.values, palette='viridis')\n",
        "plt.title('Accidents by Day of Week')\n",
        "plt.ylabel('Number of Accidents')\n",
        "plt.xlabel('')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hRaNx0mWO4Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'precip' in df.columns:\n",
        "    # bin precip into categories\n",
        "    df['rain_flag'] = (df['precip'] > 0).astype(int)\n",
        "    grp = df.groupby('rain_flag')['is_accident'].sum()\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.barplot(x=['No Rain','Rain'], y=grp.values, palette=['#4c72b0','#dd8452'])\n",
        "    plt.title('Accidents: Rain vs No Rain')\n",
        "    plt.ylabel('Number of Accidents')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping weather plot: no 'precip' column found.\")\n"
      ],
      "metadata": {
        "id": "dRmmH0RiO4SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numcols = ['hour','dayofweek','month','is_weekend','cell_rate']\n",
        "numcols += [c for c in ['precip','temp','visibility','wind_speed'] if c in df.columns]\n",
        "numcols += ['lat','lon']  # include spatial coords if desired\n",
        "corr = df[numcols + ['is_accident']].corr()\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vz98QDVIO4Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# center map\n",
        "center = [df['lat'].mean(), df['lon'].mean()]\n",
        "m = folium.Map(location=center, zoom_start=12, tiles='cartodbpositron')\n",
        "\n",
        "# prepare heat data as [lat, lon, weight]\n",
        "heat_data = df[['lat','lon','is_accident']].values.tolist()\n",
        "HeatMap([[r[0], r[1], r[2]] for r in heat_data], radius=10, blur=12, max_zoom=13).add_to(m)\n",
        "\n",
        "# save and display\n",
        "m.save('accident_hotspots.html')\n",
        "print(\"Saved Folium heatmap to accident_hotspots.html (open in browser)\")\n",
        "m  # in Jupyter this will render the map inline\n"
      ],
      "metadata": {
        "id": "ZIZBr-HqO4W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose features for modeling\n",
        "feature_cols = ['hour_sin','hour_cos','dow_sin','dow_cos','is_weekend','cell_rate']\n",
        "for c in ['precip','temp','visibility','wind_speed']:\n",
        "    if c in df.columns:\n",
        "        feature_cols.append(c)\n",
        "# optionally include lat/lon (careful about overfitting)\n",
        "feature_cols += ['lat','lon']\n",
        "\n",
        "# ensure no NaNs\n",
        "X = df[feature_cols].fillna(0)\n",
        "y = df['is_accident'].astype(int)\n",
        "\n",
        "# train-test split (stratify to maintain class imbalance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(\"Train/Test sizes:\", X_train.shape, X_test.shape)\n"
      ],
      "metadata": {
        "id": "j8lRr6vOO4Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForest\n",
        "rf = RandomForestClassifier(n_estimators=300, class_weight='balanced_subsample', random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "proba_rf = rf.predict_proba(X_test)[:,1]\n",
        "\n",
        "# XGBoost\n",
        "xgb = XGBClassifier(n_estimators=500, learning_rate=0.05, use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1)\n",
        "# compute scale_pos_weight for imbalance\n",
        "scale_pos_weight = (y_train==0).sum() / (y_train==1).sum() if (y_train==1).sum()>0 else 1\n",
        "xgb.set_params(scale_pos_weight=scale_pos_weight)\n",
        "xgb.fit(X_train, y_train)\n",
        "proba_xgb = xgb.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Stacking (meta learner = logistic regression)\n",
        "estimators = [('rf', rf), ('xgb', xgb)]\n",
        "stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=1000), n_jobs=-1, passthrough=False)\n",
        "stack.fit(X_train, y_train)\n",
        "proba_stack = stack.predict_proba(X_test)[:,1]\n"
      ],
      "metadata": {
        "id": "1AekvYYfO4cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, proba_rf)\n",
        "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, proba_xgb)\n",
        "fpr_stack, tpr_stack, _ = roc_curve(y_test, proba_stack)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr_rf, tpr_rf, label=f'RF AUC={auc(fpr_rf,tpr_rf):.3f}')\n",
        "plt.plot(fpr_xgb, tpr_xgb, label=f'XGB AUC={auc(fpr_xgb,tpr_xgb):.3f}')\n",
        "plt.plot(fpr_stack, tpr_stack, label=f'Stack AUC={auc(fpr_stack,tpr_stack):.3f}')\n",
        "plt.plot([0,1],[0,1],'k--', alpha=0.4)\n",
        "plt.title('ROC Curves')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eyaaLJcYO4ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prec_rf, recall_rf, _ = precision_recall_curve(y_test, proba_rf)\n",
        "prec_xgb, recall_xgb, _ = precision_recall_curve(y_test, proba_xgb)\n",
        "prec_stack, recall_stack, _ = precision_recall_curve(y_test, proba_stack)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(recall_rf, prec_rf, label=f'RF AP={average_precision_score(y_test, proba_rf):.3f}')\n",
        "plt.plot(recall_xgb, prec_xgb, label=f'XGB AP={average_precision_score(y_test, proba_xgb):.3f}')\n",
        "plt.plot(recall_stack, prec_stack, label=f'Stack AP={average_precision_score(y_test, proba_stack):.3f}')\n",
        "plt.title('Precision-Recall Curves')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yltK4W3fO4iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose stack; threshold 0.5\n",
        "th = 0.5\n",
        "y_pred_stack = (proba_stack >= th).astype(int)\n",
        "cm = confusion_matrix(y_test, y_pred_stack, normalize='true')  # normalize by true labels\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\".2f\", cmap='Blues', xticklabels=['No','Yes'], yticklabels=['No','Yes'])\n",
        "plt.title(f'Normalized Confusion Matrix (Stack, thresh={th})')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PWb6fvZVPa9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "prob_true, prob_pred = calibration_curve(y_test, proba_stack, n_bins=10)\n",
        "plt.plot(prob_pred, prob_true, marker='o', label='Stack')\n",
        "plt.plot([0,1],[0,1],'k--', alpha=0.4)\n",
        "plt.title('Calibration Plot (Stacked Model)')\n",
        "plt.xlabel('Mean Predicted Probability')\n",
        "plt.ylabel('Fraction of Positives')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "# Brier score\n",
        "print(\"Brier score (stack):\", brier_score_loss(y_test, proba_stack))\n"
      ],
      "metadata": {
        "id": "c7XmOWnpPdy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use the xgboost model for SHAP TreeExplainer (already trained)\n",
        "explainer = shap.TreeExplainer(xgb)\n",
        "# Due to speed, sample subset for SHAP plots (e.g., 2000 rows or full if small)\n",
        "sample_idx = np.random.choice(X_test.index, size=min(2000, len(X_test)), replace=False)\n",
        "X_shap = X_test.loc[sample_idx]\n",
        "shap_values = explainer.shap_values(X_shap)\n"
      ],
      "metadata": {
        "id": "Ixy0wpSfPfaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "shap.summary_plot(shap_values, X_shap, plot_type='bar', show=True)\n"
      ],
      "metadata": {
        "id": "g1C0_B_gPhC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat = 'precip' if 'precip' in X.columns else 'cell_rate'\n",
        "plt.figure(figsize=(8,6))\n",
        "shap.dependence_plot(feat, shap_values, X_shap, interaction_index=None, show=True)\n"
      ],
      "metadata": {
        "id": "-mC_WN20PiwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick a risky sample (highest predicted prob in test)\n",
        "idx = X_test.index[np.argmax(proba_xgb)]  # sample index with highest XGB prob\n",
        "X_sample = X_test.loc[[idx]]\n",
        "sv_sample = explainer.shap_values(X_sample)\n",
        "\n",
        "# Bar style local explanation\n",
        "# sv = sv_sample[0] if isinstance(sv_sample, (list,tuple)) else sv_sample # Original line\n",
        "sv = sv_sample[1] if isinstance(sv_sample, list) else sv_sample # Fixed line: select SHAP values for the positive class (index 1)\n",
        "feature_imp = pd.Series(sv.flatten(), index=X_sample.columns).sort_values(ascending=False) # Flatten the array before creating Series\n",
        "plt.figure(figsize=(8,4))\n",
        "feature_imp.head(10).plot(kind='barh', color='tomato')\n",
        "plt.title('Top positive SHAP contributions (sample)')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n",
        "# Optional: interactive force plot (not PNG)\n",
        "try:\n",
        "    shap.initjs()\n",
        "    display(shap.force_plot(explainer.expected_value, sv_sample, X_sample))\n",
        "except Exception as e:\n",
        "    print(\"Interactive SHAP force plot not displayed in this environment.\")"
      ],
      "metadata": {
        "id": "NR5x_9WPPl7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained models (optional) using joblib\n",
        "import joblib\n",
        "joblib.dump(rf, 'rf_model.joblib')\n",
        "joblib.dump(xgb, 'xgb_model.joblib')\n",
        "joblib.dump(stack, 'stack_model.joblib')\n",
        "\n",
        "# Save processed dataset sample for Tableau / report\n",
        "df.to_csv('accidents_processed_sample.csv', index=False)\n",
        "print(\"Saved models and processed dataset sample.\")\n"
      ],
      "metadata": {
        "id": "wHtp05iSPnrN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}